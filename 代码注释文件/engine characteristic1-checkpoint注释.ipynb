{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-03-16 15:19:12--  http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_test.txt\n",
      "Resolving tianchi-media.oss-cn-beijing.aliyuncs.com (tianchi-media.oss-cn-beijing.aliyuncs.com)... 47.95.85.21\n",
      "Connecting to tianchi-media.oss-cn-beijing.aliyuncs.com (tianchi-media.oss-cn-beijing.aliyuncs.com)|47.95.85.21|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 466959 (456K) [text/plain]\n",
      "Saving to: ‘zhengqi_test.txt.2’\n",
      "\n",
      "100%[======================================>] 466,959     --.-K/s   in 0.1s    \n",
      "\n",
      "2021-03-16 15:19:13 (3.31 MB/s) - ‘zhengqi_test.txt.2’ saved [466959/466959]\n",
      "\n",
      "--2021-03-16 15:19:13--  http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_train.txt\n",
      "Resolving tianchi-media.oss-cn-beijing.aliyuncs.com (tianchi-media.oss-cn-beijing.aliyuncs.com)... 47.95.85.21\n",
      "Connecting to tianchi-media.oss-cn-beijing.aliyuncs.com (tianchi-media.oss-cn-beijing.aliyuncs.com)|47.95.85.21|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 714370 (698K) [text/plain]\n",
      "Saving to: ‘zhengqi_train.txt.2’\n",
      "\n",
      "100%[======================================>] 714,370     --.-K/s   in 0.1s    \n",
      "\n",
      "2021-03-16 15:19:14 (4.85 MB/s) - ‘zhengqi_train.txt.2’ saved [714370/714370]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载需要用到的数据集\n",
    "!wget http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_test.txt\n",
    "!wget http://tianchi-media.oss-cn-beijing.aliyuncs.com/DSW/Industrial_Steam_Forecast/zhengqi_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_file = \"./zhengqi_train.txt\"\n",
    "test_data_file =  \"./zhengqi_test.txt\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_file, sep='\\t', encoding='utf-8')\n",
    "test_data = pd.read_csv(test_data_file, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-5\n",
    "\n",
    "#组交叉特征，可以自行定义，如增加： x*x/y, log(x)/y 等等\n",
    "#针对中小型数据集常用的一种用于观察模型稳定性的方法——交叉验证。\n",
    "\n",
    "#为啥使用组交叉特征\n",
    "#交叉验证可以用于评估模型的预测性能，尤其是训练好的模型在新数据上的表现，在一定程度上减小过拟合。\n",
    "#可以从有限的数据中获取尽可能多的有效信息。\n",
    "#在数据量较少时，更方便找到适合的模型参数。\n",
    "\n",
    "#一些lambda函数示例：\n",
    "#lambda x, y: xy；函数输入是x和y，输出是它们的积xy\n",
    "#lambda *args: sum(args); 输入是任意个数的参数，输出是它们的和(注意要求输入参数必须能够进行加法运算)\n",
    "#lambda **kwargs: 1；输入是任意键值对参数，输出是1\n",
    "\n",
    "#组合交叉验证构造加减乘除\n",
    "#构造字典是函数名称=中括号\n",
    "func_dict = {\n",
    "            'add': lambda x,y: x+y,#add加了引号,每行有逗号\n",
    "            'mins': lambda x,y: x-y,\n",
    "            'div': lambda x,y: x/(y+epsilon),\n",
    "            'multi': lambda x,y: x*y\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_features_make(train_data,test_data,func_dict,col_list):\n",
    "    #函数构造末尾是有冒号的\n",
    "    train_data, test_data = train_data.copy(), test_data.copy()#连续复制一个数据集\n",
    "    for col_i in col_list:\n",
    "        for col_j in col_list:\n",
    "            for func_name, func in func_dict.items():#返回可遍历的(键, 值) 元组数组。\n",
    "                for data in [train_data,test_data]:\n",
    "                    func_features = func(data[col_i],data[col_j])\n",
    "                    col_func_features = '-'.join([col_i,func_name,col_j])\n",
    "                    #这个join里面有中括号\n",
    "                    data[col_func_features] = func_features\n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2, test_data2 = auto_features_make(train_data,test_data,func_dict,col_list=test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA   #主成分分析法\n",
    "\n",
    "#PCA方法降维\n",
    "pca = PCA(n_components=500)#意义：PCA算法中所要保留的主成分个数n，也即保留下来的特征个数n\n",
    "#用X来训练PCA模型，同时返回降维后的数据。\n",
    "#因为PCA是一种无监督的训练，因此没有设置Y值\n",
    "train_data2_pca = pca.fit_transform(train_data2.iloc[:,0:-1])\n",
    "\n",
    "#将数据X转换成降维后的数据。当模型训练好后，对于新输入的数据，都可以用transform方法来降维。\n",
    "test_data2_pca = pca.transform(test_data2)\n",
    "\n",
    "train_data2_pca = pd.DataFrame(train_data2_pca)#注意这里是大写的DataFrame\n",
    "test_data2_pca = pd.DataFrame(test_data2_pca)\n",
    "train_data2_pca['target'] = train_data2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = train_data2[test_data2.columns].values\n",
    "y_train = train_data2['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "# ls_validation i\n",
    "from sklearn.cross_validation import KFold#from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# 5折交叉验证\n",
    "#K折交叉验证：sklearn.model_selection.KFold(n_splits=3, shuffle=False, random_state=None)\n",
    "#思路：将训练/测试数据集划分n_splits个互斥子集，每次用其中一个子集当作验证集，\n",
    "#剩下的n_splits-1个作为训练集，进行n_splits次训练和测试，得到n_splits个结果\n",
    "#n_splits：表示划分几等份\n",
    "#shuffle：在每次划分时，是否进行洗牌\n",
    "# random_state随机数种子\n",
    "\n",
    "Folds=5\n",
    "kf = KFold(len(X_train2), n_folds=Folds, shuffle=True, random_state=2019)\n",
    "\n",
    "# 记录训练和预测MSE\n",
    "MSE_DICT = {\n",
    "    'train_mse':[],\n",
    "    'test_mse':[]\n",
    "}\n",
    "\n",
    "# 线下训练预测\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，\n",
    "#同时列出数据和数据下标，\n",
    "    # lgb树模型\n",
    "    lgb_reg = lgb.LGBMRegressor(#就是LGB的一个模型\n",
    "        learning_rate=0.01,\n",
    "        max_depth=-1,\n",
    "        n_estimators=5000,\n",
    "        boosting_type='gbdt',\n",
    "        random_state=2019,\n",
    "        objective='regression',\n",
    "    )\n",
    "   \n",
    "    # 切分训练集和预测集\n",
    "    X_train_KFold, X_test_KFold = X_train2[train_index], X_train2[test_index]\n",
    "    y_train_KFold, y_test_KFold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # 训练模型\n",
    "    lgb_reg.fit(\n",
    "            X=X_train_KFold,y=y_train_KFold,\n",
    "            eval_set=[(X_train_KFold, y_train_KFold),(X_test_KFold, y_test_KFold)],\n",
    "            eval_names=['Train','Test'],\n",
    "            early_stopping_rounds=100,\n",
    "            eval_metric='MSE',\n",
    "            verbose=50\n",
    "        )\n",
    "\n",
    "\n",
    "    # 训练集预测 测试集预测\n",
    "    y_train_KFold_predict = lgb_reg.predict(X_train_KFold,num_iteration=lgb_reg.best_iteration_)\n",
    "    y_test_KFold_predict = lgb_reg.predict(X_test_KFold,num_iteration=lgb_reg.best_iteration_) \n",
    "    \n",
    "    print('第{}折 训练和预测 训练MSE 预测MSE'.format(i))\n",
    "    train_mse = mean_squared_error(y_train_KFold_predict, y_train_KFold)\n",
    "    print('------\\n', '训练MSE\\n', train_mse, '\\n------')\n",
    "    test_mse = mean_squared_error(y_test_KFold_predict, y_test_KFold)\n",
    "    print('------\\n', '预测MSE\\n', test_mse, '\\n------\\n')\n",
    "    \n",
    "    MSE_DICT['train_mse'].append(train_mse)\n",
    "    MSE_DICT['test_mse'].append(test_mse)\n",
    "print('------\\n', '训练MSE\\n', MSE_DICT['train_mse'], '\\n', np.mean(MSE_DICT['train_mse']), '\\n------')\n",
    "print('------\\n', '预测MSE\\n', MSE_DICT['test_mse'], '\\n', np.mean(MSE_DICT['test_mse']), '\\n------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
